from datetime import datetime, timedelta
import os
import re
from openpyxl import load_workbook
import pandas as pd
from collections import Counter, defaultdict
import requests
import json

from xinshili.fs_utils import get_token, detail_sheet_value


def count_no_track(file_path, column_name="å¿«é€’"):
    """ç»Ÿè®¡ 'å¿«é€’' åˆ—ä¸­æ‰€æœ‰è¡Œæ•°å’Œå†…å®¹ä¸º 'æ— è½¨è¿¹' çš„æ•°é‡"""
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        headers = [cell.value for cell in sheet[1]]
        if column_name not in headers:
            raise ValueError(f"åˆ—å '{column_name}' ä¸å­˜åœ¨ï¼")
        column_index = headers.index(column_name) + 1
        pattern = re.compile(r"^\s*æ— è½¨è¿¹\s*$", re.IGNORECASE)
        total_count = 0
        no_track_count = 0
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            cell_value = row[column_index - 1]
            if cell_value is not None:
                total_count += 1
                if pattern.match(str(cell_value)):
                    no_track_count += 1
        return total_count, no_track_count
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return 0, 0


def count_distribution_and_no_track(file_path, key_column, courier_column="å¿«é€’"):
    """
    é€šç”¨å‡½æ•°ï¼Œç»Ÿè®¡æŒ‡å®šåˆ—çš„åˆ†å¸ƒæƒ…å†µåŠå…¶å¯¹åº” "æ— è½¨è¿¹" çš„æ•°é‡ã€‚
    :param file_path: Excel æ–‡ä»¶è·¯å¾„
    :param key_column: éœ€è¦ç»Ÿè®¡çš„åˆ—å
    :param courier_column: å¿«é€’åˆ—å
    :return: å„å€¼çš„æ€»æ•°å’Œ "æ— è½¨è¿¹" æ•°é‡çš„ Counter å¯¹è±¡
    """
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        headers = [cell.value for cell in sheet[1]]
        if key_column not in headers or courier_column not in headers:
            raise ValueError(f"åˆ—å '{key_column}' æˆ– '{courier_column}' ä¸å­˜åœ¨ï¼")
        key_index = headers.index(key_column) + 1
        courier_index = headers.index(courier_column) + 1
        pattern = re.compile(r"^\s*æ— è½¨è¿¹\s*$", re.IGNORECASE)
        key_counter = Counter()
        key_no_track_counter = Counter()
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            key_value = row[key_index - 1]
            courier_status = row[courier_index - 1]
            if key_value is not None:
                key_counter[key_value] += 1
                if courier_status is not None and pattern.match(str(courier_status)):
                    key_no_track_counter[key_value] += 1
        return key_counter, key_no_track_counter
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return Counter(), Counter()


def analyze_time_segments(file_path, time_column="è®¢è´­æ—¶é—´", courier_column="å¿«é€’"):
    """
    æŒ‰æ—¶é—´æ®µï¼ˆæ¯3åˆ†é’Ÿä¸ºä¸€æ®µï¼Œå¿½ç•¥ç§’è¿›è¡Œåˆ¤æ–­ï¼‰ç»Ÿè®¡æ€»æ•°å’Œ "æ— è½¨è¿¹" çš„æ•°é‡ã€‚
    è¾“å‡ºæ—¶åŒ…æ‹¬ç§’æ˜¾ç¤ºã€‚
    """
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        headers = [cell.value for cell in sheet[1]]
        if time_column not in headers or courier_column not in headers:
            raise ValueError(f"åˆ—å '{time_column}' æˆ– '{courier_column}' ä¸å­˜åœ¨ï¼")

        time_index = headers.index(time_column) + 1
        courier_index = headers.index(courier_column) + 1
        pattern = re.compile(r"^\s*æ— è½¨è¿¹\s*$", re.IGNORECASE)

        # è¯»å–å¹¶è§£ææ•°æ®
        data = []
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            order_time = row[time_index - 1]
            courier_status = row[courier_index - 1]
            if order_time is not None and isinstance(order_time, str):
                try:
                    order_time = datetime.strptime(order_time, "%m-%d %H:%M:%S")
                    order_time_without_seconds = order_time.replace(second=0)
                    data.append((order_time, order_time_without_seconds, courier_status))
                except ValueError:
                    continue

        # æŒ‰æ—¶é—´æ®µå½’ç±»
        data.sort(key=lambda x: x[1])  # æŒ‰æ— ç§’æ—¶é—´æ’åº
        time_segments = defaultdict(list)
        if data:
            base_time = data[0][1]  # ä½¿ç”¨æ— ç§’æ—¶é—´ä½œä¸ºåŸºå‡†
            current_segment = []
            for full_time, order_time_without_seconds, courier_status in data:
                if (order_time_without_seconds - base_time).total_seconds() <= 180:  # 3åˆ†é’Ÿå†…
                    current_segment.append((full_time, courier_status))
                else:
                    time_segments[base_time].extend(current_segment)
                    base_time = order_time_without_seconds
                    current_segment = [(full_time, courier_status)]
            if current_segment:
                time_segments[base_time].extend(current_segment)

        # ç»Ÿè®¡æ¯ä¸ªæ—¶é—´æ®µçš„æ€»æ•°å’Œæ— è½¨è¿¹æ•°é‡
        segment_statistics = {}
        for segment_start, entries in time_segments.items():
            total_count = len(entries)
            no_track_count = sum(
                1 for _, courier_status in entries if courier_status is not None and pattern.match(str(courier_status)))
            segment_statistics[segment_start] = {
                "total_count": total_count,
                "no_track_count": no_track_count,
                "entries": entries,
            }

        return segment_statistics

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return {}


def handle_file(input_file):
    file_extension = os.path.splitext(input_file)[1].lower()
    file_dir = os.path.dirname(input_file)
    file_name = os.path.splitext(os.path.basename(input_file))[0]
    if file_extension == '.csv':
        xlsx_file_path = os.path.join(file_dir, f"{file_name}.xlsx")
        try:
            data = pd.read_csv(input_file, encoding='utf-8')
            data.to_excel(xlsx_file_path, index=False)
            print(f"å·²å°† CSV æ–‡ä»¶è½¬æ¢ä¸º XLSX æ–‡ä»¶ï¼š{xlsx_file_path}")
            os.remove(input_file)
            print(f"å·²åˆ é™¤åŸå§‹ CSV æ–‡ä»¶ï¼š{input_file}")
            return xlsx_file_path
        except Exception as e:
            print(f"å¤„ç† CSV æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            return None
    else:
        print("æ–‡ä»¶ä¸æ˜¯ CSV æ ¼å¼ï¼Œæ‰§è¡Œå…¶ä»–é€»è¾‘")
        return input_file


def extract_number_from_filepath(filepath):
    """
    ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶åä¸­ 'å‡ºåº“æ—¶é—´' å’Œ '_' ä¹‹é—´çš„æ•°å­—ã€‚

    å‚æ•°:
    - filepath: strï¼Œæ–‡ä»¶è·¯å¾„

    è¿”å›:
    - æå–åˆ°çš„æ•°å­—ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ï¼Œè‹¥æœªæ‰¾åˆ°ï¼Œè¿”å› None
    """
    # è·å–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„éƒ¨åˆ†ï¼‰
    filename = os.path.basename(filepath)

    # ä½¿ç”¨æ­£åˆ™åŒ¹é… 'å‡ºåº“æ—¶é—´' å’Œ '_' ä¹‹é—´çš„å†…å®¹
    match = re.search(r"å‡ºåº“æ—¶é—´(\d+)_", filename)
    if match:
        return match.group(1)
    return None


update_time = "update_time"
order_count = "order_count"
no_track_number = "no_track_number"
track_percent = "track_percent"
no_track_percent = "no_track_percent"
warehouse_condition = "warehouse_condition"
store_condition = "store_condition"
sku_condition = "sku_condition"
time_segment_condition = "time_segment_condition"
time_segment_condition = "time_segment_condition"
sum_up = "sum_up"

input_file = input("è¯·è¾“å…¥æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼š")
xlsx_path = handle_file(input_file)
# å‡ºåº“æ—¶é—´
ck_time = extract_number_from_filepath(xlsx_path)
# è·å–ä»Šå¤©çš„æ—¥æœŸ
today = datetime.today()
# è·å–ä»Šå¤©æ˜¯å‡ å·
day_of_month = today.day
# æ•°æ®map
data_map = {}

text = ""
current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
text += "\n----------------------æ—¶é—´----------------------"
text += f"\næ›´æ–°æ—¶é—´: {current_time}"
data_map[update_time] = current_time

interval_time = int(day_of_month) - int(ck_time)
text += f"\nå‡ºåº“æ—¥æœŸï¼š{ck_time}"
text += f"\nè·Ÿè¸ªæ—¥æœŸï¼š{day_of_month}"
text += f"\né—´éš”æ—¶é—´ï¼š{interval_time}"
# print(f"å‡ºåº“æ—¥æœŸï¼š{ck_time}ï¼Œè·Ÿè¸ªæ—¥æœŸï¼š{day_of_month}ï¼Œé—´éš”æ—¶é—´ï¼š{time}")

total_count, no_track_count = count_no_track(xlsx_path, column_name="å¿«é€’")
swl = round(100 - ((int(no_track_count) / int(total_count)) * 100))
# print(f"æ€»æ¡æ•°ï¼ˆé™¤åˆ—å¤´ï¼‰ï¼š{total_count}ï¼Œå†…å®¹ä¸º 'æ— è½¨è¿¹' çš„æ€»æ•°ï¼š{no_track_count}ï¼Œä¸Šç½‘ç‡ä¸ºï¼š{swl}%")
text += "\n----------------------æ¦‚è§ˆ----------------------"
text += f"\nè®¢å•æ€»æ•°ï¼š{total_count}"
text += f"\næœªä¸Šç½‘æ•°ï¼š{no_track_count}"
text += f"\nä¸Šç½‘ç‡ï¼š{swl}%"
text += f"\næœªä¸Šç½‘ç‡ï¼š{100 - swl}%"

data_map[order_count] = total_count
data_map[no_track_number] = no_track_count
data_map[track_percent] = swl
data_map[no_track_percent] = 100 - swl

text += "\n----------------------ä»“åº“åˆ†å¸ƒ----------------------"
warehouse_distribution, warehouse_no_track = count_distribution_and_no_track(
    xlsx_path, key_column="å‘è´§ä»“åº“", courier_column="å¿«é€’"
)
# print("\nå‘è´§ä»“åº“åˆ†å¸ƒæƒ…å†µï¼š")
warehouse_text = ""
lowest_swl = 101  # åˆå§‹åŒ–ä¸ºæ¯” 100 å¤§çš„å€¼
lowest_warehouse = ""  # ä¿å­˜æœ€ä½ä¸Šç½‘ç‡çš„ä»“åº“ä¿¡æ¯
for warehouse, count in warehouse_distribution.items():
    no_track_count = warehouse_no_track[warehouse]
    warehouseswl = round(100 - ((int(no_track_count) / int(count)) * 100))
    # print(f"{warehouse}: æ€»æ•° {count} æ¡ï¼Œå…¶ä¸­ 'æ— è½¨è¿¹' {no_track_count} æ¡ï¼Œä¸Šç½‘ç‡ä¸ºï¼š{warehouseswl}%")
    text += f"\n{warehouse}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{warehouseswl}%"
    warehouse_text += f"\n{warehouse}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{warehouseswl}%"
    # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
    if warehouseswl < lowest_swl:
        lowest_swl = warehouseswl
        lowest_warehouse = f"{warehouse}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{warehouseswl}%"
data_map[warehouse_condition] = warehouse_text

text += "\n----------------------åº—é“ºåˆ†å¸ƒ----------------------"
store_distribution, store_no_track_distribution = count_distribution_and_no_track(
    xlsx_path, key_column="åº—é“º", courier_column="å¿«é€’"
)
# print("\nåº—é“ºåˆ†å¸ƒåŠå¯¹åº”çš„ 'æ— è½¨è¿¹' æƒ…å†µï¼š")
store_text = ""
lowest_store = ""
lowest_swl = 101  # åˆå§‹åŒ–ä¸ºä¸€ä¸ªæ¯” 100 å¤§çš„å€¼ï¼Œç”¨äºæ¯”è¾ƒ
for store, count in store_distribution.items():
    no_track_count = store_no_track_distribution[store]
    storeswl = round(100 - ((int(no_track_count) / int(count)) * 100))
    # print(f"{store}: æ€»æ•° {count} æ¡ï¼Œå…¶ä¸­ 'æ— è½¨è¿¹' {no_track_count} æ¡ï¼Œä¸Šç½‘ç‡ä¸ºï¼š{storeswl}%")
    text += f"\n{store}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{storeswl}%"
    store_text += f"\n{store}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{storeswl}%"
    # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
    if storeswl < lowest_swl:
        lowest_swl = storeswl
        lowest_store = f"{store}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{storeswl}%"
data_map[store_condition] = store_text

text += "\n----------------------skuåˆ†å¸ƒ----------------------"
sku_distribution, sku_no_track_distribution = count_distribution_and_no_track(
    xlsx_path, key_column="sku", courier_column="å¿«é€’"
)
# print("\nSKU åˆ†å¸ƒåŠå¯¹åº”çš„ 'æ— è½¨è¿¹' æƒ…å†µï¼š")
sku_text = ""
lowest_sku = ""
lowest_swl = 101  # åˆå§‹åŒ–ä¸ºæ¯” 100 å¤§çš„å€¼
for sku, count in sku_distribution.items():
    no_track_count = sku_no_track_distribution[sku]
    skuswl = round(100 - ((int(no_track_count) / int(count)) * 100))
    # print(f"{sku}: æ€»æ•° {count} æ¡ï¼Œå…¶ä¸­ 'æ— è½¨è¿¹' {no_track_count} æ¡ï¼Œä¸Šç½‘ç‡ä¸ºï¼š{skuswl}%")
    text += f"\n{sku}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{skuswl}%"
    sku_text += f"\n{sku}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{skuswl}%"
    # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
    if skuswl < lowest_swl:
        lowest_swl = skuswl
        lowest_sku = f"{sku}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{skuswl}%"
# å°† sku_text ä¿å­˜åˆ° data_map
data_map[sku_condition] = sku_text

# åˆ†ææ—¶é—´æ®µ
text += "\n----------------------æ—¶é—´æ®µåˆ†å¸ƒ----------------------"
time_segment_analysis = analyze_time_segments(xlsx_path, time_column="è®¢è´­æ—¶é—´", courier_column="å¿«é€’")
# print("\næŒ‰æ—¶é—´æ®µç»Ÿè®¡ç»“æœï¼š")
time_segment_text = ""
lowest_segment = ""  # ä¿å­˜ä¸Šç½‘ç‡æœ€ä½çš„æ—¶é—´æ®µ
lowest_swl = 101  # åˆå§‹åŒ–ä¸ºæ¯” 100 å¤§çš„å€¼
for segment_start, stats in time_segment_analysis.items():
    segment_end = segment_start + timedelta(minutes=3)
    total_count = stats["total_count"]
    no_track_count = stats["no_track_count"]
    segmentswl = round(100 - ((int(no_track_count) / int(total_count)) * 100))
    # print(f"æ—¶é—´æ®µ {segment_start.strftime('%m-%d %H:%M:%S')} - {segment_end.strftime('%m-%d %H:%M:%S')}:")
    # print(f"  æ€»æ•°: {total_count} æ¡, å…¶ä¸­ 'æ— è½¨è¿¹': {no_track_count} æ¡ï¼Œä¸Šç½‘ç‡ä¸ºï¼š{segmentswl}%")
    text += f"\n{segment_start.strftime('%m-%d %H:%M')} - {segment_end.strftime('%m-%d %H:%M')}ï¼š è®¢å•æ€»æ•°ï¼š{total_count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{segmentswl}%"
    time_segment_text += f"\n{segment_start.strftime('%m-%d %H:%M')} - {segment_end.strftime('%m-%d %H:%M')}ï¼š è®¢å•æ€»æ•°ï¼š{total_count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{segmentswl}%"
    # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
    if segmentswl < lowest_swl:
        lowest_swl = segmentswl
        lowest_segment = f"{segment_start.strftime('%m-%d %H:%M')} - {segment_end.strftime('%m-%d %H:%M')}ï¼š è®¢å•æ€»æ•°ï¼š{total_count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{segmentswl}%"
data_map[time_segment_condition] = time_segment_text

lowest_txt = ""
lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ ä»“åº“ï¼š{lowest_warehouse}"
lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ SKUï¼š{lowest_sku}"
lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ å•†åº—ï¼š{lowest_store}"
lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ æ—¶é—´æ®µï¼š{lowest_segment}"

sum_up_text = ""
# å¦‚æœä¸‰å¤©åçš„ä¸Šç½‘ç‡æ²¡æœ‰99%ä»¥ä¸Šï¼Œé‚£ä¹ˆå°±ä¸¥é‡æœ‰é—®é¢˜ï¼›éš”å¤©åº”è¯¥è¦ ã€‹= ä¸‰åˆ†ä¹‹ä¸€ï¼Œéš”ä¸¤å¤©åº”è¯¥è¦æœ‰ã€‹=75
if (interval_time == 1):
    if (swl < 30):
        sum_up_text += "â˜ï¸æ³¨æ„ï¼šé—´éš”ç¬¬1å¤©ï¼Œä¸Šç½‘ç‡æœªè¾¾30%ï¼Œå»ºè®®è·Ÿè¿›ï¼"
        sum_up_text += lowest_txt
    else:
        if (swl >= 50):
            sum_up_text += "â˜€ï¸é—´éš”ç¬¬1å¤©ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"
        else:
            sum_up_text += "â˜€ï¸é—´éš”ç¬¬1å¤©ï¼Œä¸Šç½‘ç‡è‰¯å¥½"
elif (interval_time == 2):
    if (swl < 70):
        sum_up_text += "ğŸŒ§ï¸å¼‚å¸¸ï¼šé—´éš”ç¬¬2å¤©ï¼Œä¸Šç½‘ç‡æœªè¾¾75%ï¼Œå»ºè®®åˆ†ææ•°æ®å°è¯•å®šä½é—®é¢˜ï¼"
        sum_up_text += lowest_txt
    else:
        if (swl >= 85):
            sum_up_text += "â˜€ï¸é—´éš”ç¬¬2å¤©ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"
        else:
            sum_up_text += "â˜€ï¸é—´éš”ç¬¬2å¤©ï¼Œä¸Šç½‘ç‡è‰¯å¥½"
else:
    if (swl < 95):
        sum_up_text += f"â„ï¸â›ˆï¸ğŸŒ€âš ï¸ğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œä¸Šç½‘ç‡æœªè¾¾95%ï¼Œå¼‚å¸¸ï¼Œå®šä½é—®é¢˜åè”ç³»ä»“åº“åé¦ˆé—®é¢˜ï¼"
        sum_up_text += lowest_txt
    else:
        if (swl >= 99):
            sum_up_text += f"â˜€ï¸é—´éš”ç¬¬{interval_time}å¤©ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"
        else:
            sum_up_text += f"â˜€ï¸é—´éš”ç¬¬{interval_time}å¤©ï¼Œä¸Šç½‘ç‡è‰¯å¥½"

data_map[sum_up] = sum_up_text
text += "\n----------------------æ€»ç»“&å»ºè®®----------------------"
text += f"\n{sum_up_text}"

# æ•°æ®æ‰“å°
# print(data_map)
print(text)

# å†™å…¥é£ä¹¦åœ¨çº¿æ–‡æ¡£
tat = get_token()
detail_sheet_value(tat, [
    data_map[update_time],
    data_map[order_count],
    data_map[no_track_number],
    data_map[track_percent],
    data_map[no_track_percent],
    data_map[warehouse_condition],
    data_map[store_condition],
    data_map[sku_condition],
    data_map[time_segment_condition],
    data_map[sum_up],
], ck_time)
