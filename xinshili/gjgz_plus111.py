from datetime import datetime, date, timedelta
import os
import re
from openpyxl import load_workbook
import openpyxl
import pandas as pd
from collections import Counter, defaultdict
from dataclasses import dataclass

from xinshili.fs_utils_plus import get_token, brief_sheet_value, detail_sheet_value, ClientConstants
from xinshili.usps_utils import track
from xinshili.utils import round2, getYmd

"""
zbwè½¨è¿¹è·Ÿè¸ªåˆ†æ
"""


@dataclass(frozen=True)
class RowName:
    Tracking_No = 'Tracking No./ç‰©æµè·Ÿè¸ªå·'
    Courier = 'Courier/å¿«é€’'
    OutboundTime = "OutboundTime/å‡ºåº“æ—¶é—´"
    Warehouse = "Warehouse/ä»“åº“"
    Client = "Client/å®¢æˆ·"
    CreationTime = "Creation time/åˆ›å»ºæ—¶é—´"
    SKU = "SKU"


@dataclass(frozen=True)
class CourierStateMapKey:
    tracking_map = 'tracking_map'
    no_tracking_map = 'no_tracking_map'
    unpaid_map = "unpaid_map"
    not_yet_map = "not_yet_map"
    pre_ship_map = "pre_ship_map"
    delivered_map = "delivered_map"
    irregular_number_map = "irregular_number_map"


class CourierStateMapValue:
    irregular_no_tracking = 'irregular_no_tracking'
    not_yet = 'not_yet'
    pre_ship = "pre_ship"
    no_tracking = "no_tracking"
    unpaid = "unpaid"
    delivered = "delivered"
    tracking = "tracking"


@dataclass(frozen=True)
class CellKey:
    update_time = "update_time"
    order_count = "order_count"
    no_track_number = "no_track_number"
    track_percent = "track_percent"
    delivered_counts = "delivered_counts"
    delivered_percent = "delivered_percent"
    no_track_percent = "no_track_percent"
    warehouse_condition = "warehouse_condition"
    store_condition = "store_condition"
    sku_condition = "sku_condition"
    time_segment_condition = "time_segment_condition"
    sum_up = "sum_up"


@dataclass(frozen=True)
class Pattern:
    no_track = r"not_yet|pre_ship|irregular_no_tracking|no_tracking"
    delivered = r"delivered"


def update_courier_status(filepath, maps):
    wb = openpyxl.load_workbook(filepath)
    sheet = wb.active  # é»˜è®¤ä½¿ç”¨æ´»åŠ¨å·¥ä½œè¡¨

    data = pd.read_excel(filepath)
    # è·å– 'Tracking No./ç‰©æµè·Ÿè¸ªå·' åˆ—å’Œ 'Courier/å¿«é€’' åˆ—çš„ç´¢å¼•
    tracking_no_col = data.columns.get_loc(RowName.Tracking_No) + 1  # openpyxlç´¢å¼•ä»1å¼€å§‹
    courier_col = data.columns.get_loc(RowName.Courier) + 1  # openpyxlç´¢å¼•ä»1å¼€å§‹

    for tracking_no, status in maps.items():
        for row in range(2, sheet.max_row + 1):  # ä»ç¬¬äºŒè¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            # è·å–å½“å‰è¡Œçš„ç‰©æµè·Ÿè¸ªå·
            current_tracking_no = sheet.cell(row=row, column=tracking_no_col).value
            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„ç‰©æµè·Ÿè¸ªå·ï¼Œæ›´æ–° Courier/å¿«é€’ åˆ—
            if current_tracking_no == tracking_no:
                sheet.cell(row=row, column=courier_col, value=status)
                break  # æ‰¾åˆ°åé€€å‡ºå¾ªç¯ï¼Œé¿å…é‡å¤æ›´æ–°åŒä¸€è¡Œ

    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    wb.save(filepath)


def extract_and_process_data(filepath, column_name, group_size):
    data = pd.read_excel(filepath)

    if column_name not in data.columns:
        raise ValueError(f"åˆ— '{column_name}' ä¸å­˜åœ¨äº Excel æ–‡ä»¶ä¸­")

    # å­˜å‚¨ç»“æœçš„ mapï¼ˆå­—å…¸ï¼‰
    results_map = {
        CourierStateMapKey.tracking_map: {},
        CourierStateMapKey.no_tracking_map: {},
        CourierStateMapKey.unpaid_map: {},
        CourierStateMapKey.not_yet_map: {},
        CourierStateMapKey.pre_ship_map: {},
        CourierStateMapKey.delivered_map: {},
        CourierStateMapKey.irregular_number_map: {},
    }

    # ä¸è§„åˆ™çš„å¿«é€’å•å·ä¸éœ€è¦è·Ÿè¸ª
    for tracking_number in data[RowName.Tracking_No]:
        # ä¸æ˜¯çº¯æ•°å­— æˆ–è€… ä¸æ˜¯9å¼€å¤´ çš„éƒ½ä¸ºä¸è§„åˆ™ å¿«é€’å•å·
        if not str(tracking_number).isdigit() or not str(tracking_number).startswith('9'):
            results_map[CourierStateMapKey.irregular_number_map][
                tracking_number] = CourierStateMapValue.irregular_no_tracking
    update_courier_status(filepath, results_map[CourierStateMapKey.irregular_number_map])

    # å°†æ— å†…å®¹çš„å•å…ƒæ ¼èµ‹å€¼""ç©ºå­—ç¬¦ä¸²ã€‚
    data[column_name] = data[column_name].fillna('')

    # è·å–æŒ‡å®šå†…å®¹çš„æ•°æ®
    filtered_data = data[data[column_name].apply(
        lambda x: str(x).strip().lower() in ['',
                                             CourierStateMapValue.not_yet,
                                             CourierStateMapValue.pre_ship,
                                             CourierStateMapValue.tracking,
                                             CourierStateMapValue.no_tracking])]

    # æå–ç¬¦åˆæ¡ä»¶çš„ 'Tracking No./ç‰©æµè·Ÿè¸ªå·' åˆ—æ•°æ®
    items = filtered_data[RowName.Tracking_No].tolist()

    # æŒ‰ç»„åˆ’åˆ†æ•°æ®
    grouped_items = [items[i:i + group_size] for i in range(0, len(items), group_size)]

    # è¯·æ±‚æ¯ç»„æ•°æ®
    for idx, group in enumerate(grouped_items, start=1):
        print(f"å¤„ç†ç¬¬ {idx} ç»„ï¼Œå…± {len(group)} æ¡æ•°æ®")
        track1 = track(group)  # å‡è®¾trackæ˜¯æŸ¥è¯¢APIçš„å‡½æ•°

        for package_id, info in track1['data'].items():
            # åˆ¤æ–­é”™è¯¯ç±»å‹å¹¶åˆ†ç±»
            if info.get('err'):
                if info.get('err_id') == '-2147219283':  # æ— è½¨è¿¹(Label Created, not yet in system)
                    results_map[CourierStateMapKey.not_yet_map][package_id] = CourierStateMapValue.not_yet
                elif info.get('err_id') == 'pre-ship':  # æ— è½¨è¿¹(pre-ship)
                    results_map[CourierStateMapKey.pre_ship_map][package_id] = CourierStateMapValue.pre_ship
                else:
                    results_map[CourierStateMapKey.no_tracking_map][package_id] = CourierStateMapValue.no_tracking
            else:
                if "The package associated with this tracking number did not have proper postage applied and will not be delivered" in \
                        info.get('statusLong'):
                    results_map[CourierStateMapKey.unpaid_map][package_id] = CourierStateMapValue.unpaid
                elif "Delivered" in info.get('statusCategory'):
                    results_map[CourierStateMapKey.delivered_map][package_id] = CourierStateMapValue.delivered
                elif "Delivered to Agent" in info.get('statusCategory'):
                    results_map[CourierStateMapKey.delivered_map][package_id] = CourierStateMapValue.delivered
                else:
                    results_map[CourierStateMapKey.tracking_map][package_id] = CourierStateMapValue.tracking

    return results_map


def count_pattern_state(file_path, column_name, patternStr):
    """
    ç»Ÿè®¡æŒ‡å®šåˆ—æŒ‡å®šå†…å®¹çš„æ•°é‡
    """
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        headers = [cell.value for cell in sheet[1]]
        if column_name not in headers:
            raise ValueError(f"åˆ—å '{column_name}' ä¸å­˜åœ¨ï¼")
        column_index = headers.index(column_name) + 1
        pattern = re.compile(patternStr, re.IGNORECASE)
        total_count = 0
        no_track_count = 0
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            cell_value = row[column_index - 1]
            if cell_value is not None:
                total_count += 1
                if pattern.search(str(cell_value)):
                    no_track_count += 1
        return total_count, no_track_count
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return 0, 0


def count_distribution_and_no_track(file_path, key_column, courier_column=RowName.Courier):
    """
    é€šç”¨å‡½æ•°ï¼Œç»Ÿè®¡æŒ‡å®šåˆ—çš„åˆ†å¸ƒæƒ…å†µåŠå…¶å¯¹åº” "æ— è½¨è¿¹" çš„æ•°é‡ã€‚
    :param file_path: Excel æ–‡ä»¶è·¯å¾„
    :param key_column: éœ€è¦ç»Ÿè®¡çš„åˆ—å
    :param courier_column: å¿«é€’åˆ—å
    :return: å„å€¼çš„æ€»æ•°å’Œ "æ— è½¨è¿¹" æ•°é‡çš„ Counter å¯¹è±¡
    """
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        headers = [cell.value for cell in sheet[1]]
        if key_column not in headers or courier_column not in headers:
            raise ValueError(f"åˆ—å '{key_column}' æˆ– '{courier_column}' ä¸å­˜åœ¨ï¼")
        key_index = headers.index(key_column) + 1
        courier_index = headers.index(courier_column) + 1
        pattern = re.compile(Pattern.no_track, re.IGNORECASE)
        key_counter = Counter()
        key_no_track_counter = Counter()
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            key_value = row[key_index - 1]
            courier_status = row[courier_index - 1]
            if key_value is not None:
                key_counter[key_value] += 1
                if courier_status is not None and pattern.search(str(courier_status)):
                    key_no_track_counter[key_value] += 1
        return key_counter, key_no_track_counter
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return Counter(), Counter()


def analyze_time_segments(file_path, time_column, courier_column):
    """
    æŒ‰æ—¶é—´æ®µï¼ˆæ¯3åˆ†é’Ÿä¸ºä¸€æ®µï¼Œå¿½ç•¥ç§’è¿›è¡Œåˆ¤æ–­ï¼‰ç»Ÿè®¡æ€»æ•°å’Œ "æ— è½¨è¿¹" çš„æ•°é‡ã€‚
    è¾“å‡ºæ—¶åŒ…æ‹¬ç§’æ˜¾ç¤ºã€‚
    """
    try:
        # åŠ è½½ Excel æ–‡ä»¶
        workbook = load_workbook(file_path)
        sheet = workbook.active

        # è·å–è¡¨å¤´
        headers = [cell.value for cell in sheet[1]]
        if time_column not in headers or courier_column not in headers:
            raise ValueError(f"åˆ—å '{time_column}' æˆ– '{courier_column}' ä¸å­˜åœ¨ï¼")

        # è·å–åˆ—ç´¢å¼•
        time_index = headers.index(time_column) + 1
        courier_index = headers.index(courier_column) + 1

        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… "æ— è½¨è¿¹"
        pattern = re.compile(Pattern.no_track, re.IGNORECASE)

        # è¯»å–å¹¶è§£ææ•°æ®
        data = []
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):
            order_time = row[time_index - 1]
            courier_status = row[courier_index - 1]
            if order_time is not None and isinstance(order_time, str):
                try:
                    # è§£ææ—¶é—´æ ¼å¼ä¸º "2025-01-22 23:11:43"
                    order_time = datetime.strptime(order_time, "%Y-%m-%d %H:%M:%S")
                    order_time_without_seconds = order_time.replace(second=0)
                    data.append((order_time, order_time_without_seconds, courier_status))
                except ValueError:
                    continue

        # æŒ‰æ—¶é—´æ®µå½’ç±»
        data.sort(key=lambda x: x[1])  # æŒ‰æ— ç§’æ—¶é—´æ’åº
        time_segments = defaultdict(list)
        if data:
            base_time = data[0][1]  # ä½¿ç”¨æ— ç§’æ—¶é—´ä½œä¸ºåŸºå‡†
            current_segment = []
            for full_time, order_time_without_seconds, courier_status in data:
                if (order_time_without_seconds - base_time).total_seconds() <= 180:  # 3åˆ†é’Ÿå†…
                    current_segment.append((full_time, courier_status))
                else:
                    time_segments[base_time].extend(current_segment)
                    base_time = order_time_without_seconds
                    current_segment = [(full_time, courier_status)]
            if current_segment:
                time_segments[base_time].extend(current_segment)

        # ç»Ÿè®¡æ¯ä¸ªæ—¶é—´æ®µçš„æ€»æ•°å’Œæ— è½¨è¿¹æ•°é‡
        segment_statistics = {}
        for segment_start, entries in time_segments.items():
            total_count = len(entries)
            no_track_count = sum(
                1 for _, courier_status in entries if courier_status is not None and pattern.match(str(courier_status)))
            segment_statistics[segment_start] = {
                "total_count": total_count,
                "no_track_count": no_track_count,
                "entries": entries,
            }

        return segment_statistics

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return {}


def check_and_add_courier_column(file_path, courier_column=RowName.Courier):
    """
    æ£€æŸ¥ Excel æ–‡ä»¶æ˜¯å¦å­˜åœ¨ 'å¿«é€’' åˆ—ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™åœ¨æœ€åä¸€åˆ—æ·»åŠ è¯¥åˆ—ã€‚

    :param file_path: Excel æ–‡ä»¶è·¯å¾„
    :param courier_column: å¿«é€’åˆ—åï¼Œé»˜è®¤ä¸º 'Courier/å¿«é€’'
    :return: None
    """
    try:
        # åŠ è½½ Excel æ–‡ä»¶
        data = pd.read_excel(file_path, engine='openpyxl')
        # åˆ¤æ–­æ˜¯å¦å­˜åœ¨ 'å¿«é€’' åˆ—
        if courier_column not in data.columns:
            # å¦‚æœæ²¡æœ‰ 'å¿«é€’' åˆ—ï¼Œåˆ™åœ¨æœ€åä¸€åˆ—æ·»åŠ è¯¥åˆ—
            data[courier_column] = ""  # é»˜è®¤ä¸ºç©ºå€¼ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚å¡«å……å…¶ä»–é»˜è®¤å€¼
            # ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶
            data.to_excel(file_path, index=False, engine='openpyxl')
        #     print(f"åˆ— '{courier_column}' å·²æ·»åŠ åˆ°æ–‡ä»¶ä¸­ï¼Œå¹¶ä¿å­˜ã€‚")
        # else:
        #     print(f"åˆ— '{courier_column}' å·²å­˜åœ¨ï¼Œæ— éœ€æ·»åŠ ã€‚")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")


def get_days_difference(file_path, column_name=RowName.OutboundTime):
    try:
        workbook = load_workbook(file_path)
        sheet = workbook.active
        # è·å–è¡¨å¤´
        headers = [cell.value for cell in sheet[1]]
        if column_name not in headers:
            raise ValueError(f"åˆ—å '{column_name}' ä¸å­˜åœ¨ï¼")
        # è·å–åˆ—ç´¢å¼•
        column_index = headers.index(column_name) + 1
        # è·å–ç¬¬ä¸€æ¡æ•°æ®
        first_row_value = sheet.cell(row=2, column=column_index).value  # å‡è®¾æ•°æ®ä»ç¬¬äºŒè¡Œå¼€å§‹
        if not first_row_value:
            raise ValueError(f"'{column_name}' åˆ—çš„ç¬¬ä¸€æ¡æ•°æ®ä¸ºç©ºï¼")
        # è§£ææ—¥æœŸ
        outbound_time = datetime.strptime(first_row_value, "%Y-%m-%d %H:%M:%S")
        # æ ¼å¼åŒ–ä¸º "%Y/%m/%d" æ ¼å¼
        formatted_date = outbound_time.strftime("%Y/%m/%d")
        return formatted_date
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return None


def remove_duplicates_by_column(input_file, output_file, column_name):
    """
    åˆ é™¤æŒ‡å®šåˆ—ä¸­é‡å¤çš„è¡Œï¼Œä»…ä¿ç•™ç¬¬ä¸€æ¡ï¼Œå¹¶è¦†ç›–æºæ–‡ä»¶ã€‚

    å‚æ•°ï¼š
    - input_file: strï¼Œè¾“å…¥æ–‡ä»¶è·¯å¾„
    - column_name: strï¼Œè¦æ£€æŸ¥é‡å¤çš„åˆ—å
    """
    try:
        # è¯»å– Excel æ–‡ä»¶
        df = pd.read_excel(input_file)
        # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
        if column_name not in df.columns:
            raise ValueError(f"åˆ— '{column_name}' ä¸å­˜åœ¨äºè¾“å…¥æ–‡ä»¶ä¸­ï¼")
        # åˆ é™¤æŒ‡å®šåˆ—çš„é‡å¤é¡¹ï¼Œä»…ä¿ç•™ç¬¬ä¸€æ¡
        df_deduplicated = df.drop_duplicates(subset=[column_name], keep='first')
        df_deduplicated.to_excel(output_file, index=False)
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")


def generate_distribution_report(distribution, no_track_distribution, data_map, data_map_key):
    """
    é€šç”¨çš„åˆ†å¸ƒæŠ¥å‘Šç”Ÿæˆå‡½æ•°
    :param distribution: è®¢å•åˆ†å¸ƒå­—å…¸
    :param no_track_distribution: æ— è½¨è¿¹åˆ†å¸ƒå­—å…¸
    :param data_map:
    :param data_map_key: ç”¨äºå­˜å‚¨åˆ° `data_map` çš„ keyï¼ˆä¾‹å¦‚ `CellKey.warehouse_condition` æˆ– `CellKey.store_condition`ï¼‰
    :return: ç”Ÿæˆçš„åˆ†å¸ƒæŠ¥å‘Šæ–‡æœ¬
    """
    report_text = ""
    lowest_swl = 101  # åˆå§‹åŒ–ä¸ºä¸€ä¸ªæ¯” 100 å¤§çš„å€¼ï¼Œç”¨äºæ¯”è¾ƒ
    lowest_entity = ""  # ä¿å­˜æœ€ä½ä¸Šç½‘ç‡çš„å®ä½“ä¿¡æ¯

    # éå†åˆ†å¸ƒæ•°æ®
    for entity, count in distribution.items():
        no_track_count = no_track_distribution.get(entity, 0)
        swl = round2(100 - ((int(no_track_count) / int(count)) * 100))
        strs = f"\n{entity}ï¼š è®¢å•æ€»æ•°ï¼š{count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{swl}%"
        report_text += strs

        # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
        if swl < lowest_swl:
            lowest_swl = swl
            lowest_entity = strs

    data_map[data_map_key] = report_text  # å°†ç»“æœå­˜å‚¨åˆ° data_map ä¸­
    return report_text, lowest_entity


def go():
    analyse_obj = input("è¯·è¾“è·Ÿè¸ªå¯¹è±¡ï¼ˆzbw/sanrioï¼‰ï¼š")
    if analyse_obj != ClientConstants.zbw and analyse_obj != ClientConstants.sanrio:
        raise ValueError(f"{analyse_obj} æœªå®šä¹‰")

    xlsx_path = input("è¯·è¾“å…¥æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼š")
    check_and_add_courier_column(xlsx_path)
    results = extract_and_process_data(xlsx_path, RowName.Courier, 100)

    # no_tracking_count = len(results[CourierStateMapKey.not_yet_results]) + len(
    #     results[CourierStateMapKey.pre_ship_results]) + len(results[CourierStateMapKey.no_tracking_results])
    # tracking_count = len(results[CourierStateMapKey.unpaid_results]) + len(
    #     results[CourierStateMapKey.delivered_results]) + len(results[CourierStateMapKey.tracking_results])
    # print(f"æ²¡æœ‰è½¨è¿¹æ•°ï¼š {no_tracking_count} æ¡ï¼Œæœ‰è½¨è¿¹æ•°ï¼š {tracking_count} æ¡")
    # print(f"\nunpaidæ•°ï¼š {len(results[CourierStateMapKey.unpaid_results])} æ¡")
    # print(f"\nnot_yetæ•°ï¼š {len(results[CourierStateMapKey.not_yet_results])} æ¡")
    # print(f"\npre_shipæ•°ï¼š {len(results[CourierStateMapKey.pre_ship_results])} æ¡")
    # print(f"\ndeliveredæ•°ï¼š {len(results[CourierStateMapKey.delivered_results])} æ¡")

    update_courier_status(xlsx_path, results[CourierStateMapKey.not_yet_map])
    update_courier_status(xlsx_path, results[CourierStateMapKey.pre_ship_map])
    update_courier_status(xlsx_path, results[CourierStateMapKey.unpaid_map])
    update_courier_status(xlsx_path, results[CourierStateMapKey.delivered_map])
    update_courier_status(xlsx_path, results[CourierStateMapKey.no_tracking_map])
    update_courier_status(xlsx_path, results[CourierStateMapKey.tracking_map])

    ck_time = get_days_difference(xlsx_path)
    gz_time = getYmd()
    interval_time = (datetime.strptime(gz_time, "%Y/%m/%d") - datetime.strptime(ck_time, "%Y/%m/%d")).days

    # æ•°æ®map
    data_map = {}

    text = ""

    text += "\n----------------------SKUåˆ†å¸ƒ----------------------"
    sku_distribution, sku_no_track_distribution = count_distribution_and_no_track(xlsx_path, key_column=RowName.SKU)
    sku_text, lowest_sku = generate_distribution_report(
        sku_distribution, sku_no_track_distribution, data_map, CellKey.sku_condition
    )
    text += sku_text

    output_file = os.path.splitext(xlsx_path)[0] + "_å»é‡.xlsx"
    # éœ€è¦å»é‡å¤
    remove_duplicates_by_column(xlsx_path, output_file, RowName.Tracking_No)

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    text += "\n----------------------æ—¶é—´----------------------"
    text += f"\næ›´æ–°æ—¶é—´: {current_time}"
    data_map[CellKey.update_time] = current_time

    text += f"\nå‡ºåº“æ—¥æœŸï¼š{ck_time}"
    text += f"\nè·Ÿè¸ªæ—¥æœŸï¼š{gz_time}"
    text += f"\né—´éš”æ—¶é—´ï¼š{interval_time}"

    total_count, no_track_count = count_pattern_state(output_file, RowName.Courier, Pattern.no_track)
    total_count2, delivered_count = count_pattern_state(output_file, RowName.Courier, Pattern.delivered)

    qsl = round2((int(delivered_count) / int(total_count)) * 100)
    swl = round2(100 - ((int(no_track_count) / int(total_count)) * 100))
    text += "\n----------------------æ¦‚è§ˆ----------------------"
    text += f"\nè®¢å•æ€»æ•°ï¼š{total_count}"
    text += f"\nç­¾æ”¶æ•°ï¼š{delivered_count}"
    text += f"\nç­¾æ”¶ç‡ï¼š{qsl}%"
    text += f"\næœªä¸Šç½‘æ•°ï¼š{no_track_count}"
    text += f"\nä¸Šç½‘ç‡ï¼š{swl}%"
    text += f"\næœªä¸Šç½‘ç‡ï¼š{100 - swl}%"

    data_map[CellKey.order_count] = total_count
    data_map[CellKey.no_track_number] = no_track_count
    data_map[CellKey.track_percent] = swl
    data_map[CellKey.no_track_percent] = 100 - swl
    data_map[CellKey.delivered_counts] = delivered_count
    data_map[CellKey.delivered_percent] = qsl

    text += "\n----------------------ä»“åº“åˆ†å¸ƒ----------------------"
    warehouse_distribution, warehouse_no_track = count_distribution_and_no_track(output_file,
                                                                                 key_column=RowName.Warehouse)
    warehouse_text, lowest_warehouse = generate_distribution_report(
        warehouse_distribution, warehouse_no_track, data_map, CellKey.warehouse_condition
    )
    text += warehouse_text

    text += "\n----------------------åº—é“ºåˆ†å¸ƒ----------------------"
    store_distribution, store_no_track_distribution = count_distribution_and_no_track(
        output_file, key_column=RowName.Client)
    store_text, lowest_store = generate_distribution_report(
        store_distribution, store_no_track_distribution, data_map, CellKey.store_condition
    )
    text += store_text

    # åˆ†ææ—¶é—´æ®µ
    text += "\n----------------------æ—¶é—´æ®µåˆ†å¸ƒ----------------------"
    time_segment_analysis = analyze_time_segments(
        output_file, time_column=RowName.CreationTime, courier_column=RowName.Courier
    )
    # print("\næŒ‰æ—¶é—´æ®µç»Ÿè®¡ç»“æœï¼š")
    time_segment_text = ""
    lowest_segment = ""  # ä¿å­˜ä¸Šç½‘ç‡æœ€ä½çš„æ—¶é—´æ®µ
    lowest_swl = 101  # åˆå§‹åŒ–ä¸ºæ¯” 100 å¤§çš„å€¼
    for segment_start, stats in time_segment_analysis.items():
        segment_end = segment_start + timedelta(minutes=3)
        total_count = stats["total_count"]
        no_track_count = stats["no_track_count"]
        segmentswl = round2(100 - ((int(no_track_count) / int(total_count)) * 100))
        strs = f"\n{segment_start.strftime('%y-%m-%d %H:%M')} - {segment_end.strftime('%y-%m-%d %H:%M')}ï¼š è®¢å•æ€»æ•°ï¼š{total_count}ï¼›æ— è½¨è¿¹æ•°ï¼š{no_track_count}ï¼›ä¸Šç½‘ç‡ï¼š{segmentswl}%"
        text += strs
        time_segment_text += strs
        # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½çš„ä¸Šç½‘ç‡
        if segmentswl < lowest_swl:
            lowest_swl = segmentswl
            lowest_segment = strs
    data_map[CellKey.time_segment_condition] = time_segment_text

    lowest_txt = ""
    lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ ä»“åº“ï¼š{lowest_warehouse}"
    lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ SKUï¼š{lowest_sku}"
    lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ å•†åº—ï¼š{lowest_store}"
    lowest_txt += f"\næœ€ä½ä¸Šç½‘ç‡çš„ æ—¶é—´æ®µï¼š{lowest_segment}"

    sum_up_text = ""
    # å¦‚æœä¸‰å¤©åçš„ä¸Šç½‘ç‡æ²¡æœ‰99%ä»¥ä¸Šï¼Œé‚£ä¹ˆå°±ä¸¥é‡æœ‰é—®é¢˜ï¼›éš”å¤©åº”è¯¥è¦ ã€‹= ä¸‰åˆ†ä¹‹ä¸€ï¼Œéš”ä¸¤å¤©åº”è¯¥è¦æœ‰ã€‹=75
    if (interval_time == 1):
        if (swl < 30):
            sum_up_text += f"â˜ï¸æ³¨æ„ï¼šé—´éš”ç¬¬1å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œæœªè¾¾30%ï¼Œå»ºè®®è·Ÿè¿›ï¼"
            sum_up_text += lowest_txt
        else:
            sum_up_text += f"â˜€ï¸é—´éš”ç¬¬1å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"
    elif (interval_time == 2):
        if (swl < 70):
            sum_up_text += f"ğŸŒ§ï¸å¼‚å¸¸ï¼šé—´éš”ç¬¬2å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œæœªè¾¾75%ï¼Œå»ºè®®åˆ†ææ•°æ®å°è¯•å®šä½é—®é¢˜ï¼"
            sum_up_text += lowest_txt
        else:
            sum_up_text += f"â˜€ï¸é—´éš”ç¬¬2å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"
    else:  # é—´éš”æ—¶é—´ >= 3å¤©
        if (swl < 97):
            sum_up_text += f"â„ï¸â›ˆï¸ğŸŒ€âš ï¸ğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œæœªè¾¾97%ï¼Œåˆ†ææ•°æ®åé¦ˆé—®é¢˜ï¼"
            sum_up_text += lowest_txt
        else:
            sum_up_text += f"â˜€ï¸é—´éš”ç¬¬{interval_time}å¤©ï¼Œä¸Šç½‘ç‡ä¸º{swl}ï¼Œä¸Šç½‘ç‡ä¼˜ç§€"

    # è¦æŒç»­ç›‘æ§ä¸€ä¸ªæ˜ŸæœŸæ‰è¡Œï¼Œä»å‡ºåº“å¼€å§‹è®¡ç®—ï¼Œä¸‰å¤©å†…æ²¡æœ‰ç­¾æ”¶çš„ä¸æ­£å¸¸ï¼Œäº”å¤©å†…ç­¾æ”¶æ²¡è¾¾åˆ°50%ä¹Ÿä¸æ­£å¸¸ï¼Œ7å¤©å†…æ²¡åˆ°90ä¹Ÿä¸æ­£å¸¸
    if (interval_time >= 1 and interval_time <= 3):
        if (interval_time >= 2 and qsl == 0):
            sum_up_text += f"\nğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º0%ï¼Œå¼‚å¸¸çŠ¶æ€ï¼"
        else:
            sum_up_text += f"\né—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œç»§ç»­è·Ÿè¿›ï¼"
    elif (interval_time > 3 and interval_time <= 5):
        if (qsl <= 35):
            sum_up_text += f"\nğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œå¼‚å¸¸çŠ¶æ€ï¼"
        else:
            sum_up_text += f"\né—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œç»§ç»­è·Ÿè¿›ï¼"
    elif (interval_time > 5 and interval_time <= 7):
        if (qsl <= 80):
            sum_up_text += f"\nğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œå¼‚å¸¸çŠ¶æ€ï¼"
        else:
            sum_up_text += f"\né—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œç»§ç»­è·Ÿè¿›ï¼"
    elif (interval_time > 7 and interval_time <= 9):
        if (qsl <= 95):
            sum_up_text += f"\nğŸš¨è­¦æŠ¥ï¼šé—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œå¼‚å¸¸çŠ¶æ€ï¼"
        else:
            sum_up_text += f"\né—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œç»§ç»­è·Ÿè¿›ï¼"
    else:
        sum_up_text += f"\né—´éš”ç¬¬{interval_time}å¤©ï¼Œç­¾æ”¶ç‡ä¸º{qsl}%ï¼Œç»§ç»­è·Ÿè¿›ï¼"

    data_map[CellKey.sum_up] = sum_up_text
    text += "\n----------------------æ€»ç»“&å»ºè®®----------------------"
    text += f"\n{sum_up_text}"

    # æ•°æ®æ‰“å°
    # print(data_map)
    print(text)

    # å†™å…¥é£ä¹¦åœ¨çº¿æ–‡æ¡£
    tat = get_token()
    brief_sheet_value(tat, [swl], ck_time, gz_time, analyse_obj)
    detail_sheet_value(tat, [
        data_map[CellKey.update_time],
        data_map[CellKey.order_count],
        data_map[CellKey.delivered_counts],
        data_map[CellKey.delivered_percent],
        data_map[CellKey.no_track_number],
        data_map[CellKey.track_percent],
        data_map[CellKey.no_track_percent],
        data_map[CellKey.warehouse_condition],
        data_map[CellKey.store_condition],
        data_map[CellKey.sku_condition],
        data_map[CellKey.time_segment_condition],
        data_map[CellKey.sum_up],
    ], ck_time, analyse_obj)


if __name__ == '__main__':
    go()
